{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix as cmat\n",
    "import collections\n",
    "import itertools\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report as report  \n",
    "from sklearn.model_selection import *\n",
    "from sklearn.feature_selection import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import numpy\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import xarray as xr\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Papa CTD Data:\n",
    "\n",
    "url = 'https://opendap.oceanobservatories.org/thredds/catalog/ooi/mvalera-w@sdsu.edu/20180822T010245-GP02HYPM-WFP02-04-CTDPFL000-recovered_wfp-ctdpf_ckl_wfp_instrument_recovered/catalog.html'\n",
    "tds_url = 'https://opendap.oceanobservatories.org/thredds/dodsC'\n",
    "datasets = requests.get(url).text\n",
    "urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', datasets)\n",
    "x = re.findall(r'(ooi/.*?.nc)', datasets)\n",
    "for i in x:\n",
    "    if i.endswith('.nc') == False:\n",
    "        x.remove(i)\n",
    "for i in x:\n",
    "    try:\n",
    "        float(i[-4])\n",
    "    except:\n",
    "        x.remove(i)\n",
    "        \n",
    "datasets = [os.path.join(tds_url, i) for i in x]\n",
    "datasets\n",
    "\n",
    "# Chunk it:\n",
    "\n",
    "ds = xr.open_mfdataset(datasets)\n",
    "ds = ds.swap_dims({'obs': 'time'})\n",
    "ds = ds.chunk({'time': 100})\n",
    "ds = ds.sortby('time') # data from different deployments can overlap so we want to sort all data by time stamp.\n",
    "# Dropping not needed coordinates:\n",
    "ds2 = ds.drop(['time','obs','pressure','lat','lon'], dim=None)\n",
    "ds2\n",
    "\n",
    "g_temp = ds2.ctdpf_ckl_seawater_temperature.to_dataframe()\n",
    "#g_temp = g_temp.rename(columns={'ctdpf_ckl_seawater_temperature': 'temp'})\n",
    "\n",
    "g_salinity = ds2.practical_salinity.to_dataframe()\n",
    "#g_salinity = g_salinity.rename(columns={'practical_salinity': 'sal'})\n",
    "\n",
    "g_pressure = ds2.ctdpf_ckl_seawater_pressure.to_dataframe()\n",
    "\n",
    "g_conductivity = ds2.ctdpf_ckl_seawater_conductivity.to_dataframe()\n",
    "\n",
    "g_density = ds2.density.to_dataframe()\n",
    "\n",
    "# Joining tables to create dataset:\n",
    "papa_ctd = pd.concat([g_temp, g_salinity, g_conductivity, g_density],axis=1, join_axes=[g_temp.index])\n",
    "\n",
    "#Add a column for labeling: \n",
    "\n",
    "papa_ctd['Label']=1\n",
    "\n",
    "\n",
    "papa_rows = papa_ctd['Label'].shape\n",
    "\n",
    "# Decimate to 10% to make it faster:\n",
    "\n",
    "bins = int(.01*papa_rows[0]) #Saving only 10% because is just too much\n",
    "\n",
    "papa_file = papa_ctd.groupby(pd.qcut(papa_ctd.index,bins)).mean()\n",
    "\n",
    "\n",
    "papa_file.to_csv('papa_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GS Dataset:\n",
    "url = 'https://opendap.oceanobservatories.org/thredds/catalog/ooi/mvalera-w@sdsu.edu/20180822T185654-GS02HYPM-WFP02-04-CTDPFL000-recovered_wfp-ctdpf_ckl_wfp_instrument_recovered/catalog.html'\n",
    "tds_url = 'https://opendap.oceanobservatories.org/thredds/dodsC'\n",
    "datasets = requests.get(url).text\n",
    "urls = re.findall(r'href=[\\'\"]?([^\\'\" >]+)', datasets)\n",
    "x = re.findall(r'(ooi/.*?.nc)', datasets)\n",
    "for i in x:\n",
    "    if i.endswith('.nc') == False:\n",
    "        x.remove(i)\n",
    "for i in x:\n",
    "    try:\n",
    "        float(i[-4])\n",
    "    except:\n",
    "        x.remove(i)\n",
    "        \n",
    "datasets = [os.path.join(tds_url, i) for i in x]\n",
    "datasets\n",
    "\n",
    "# Chunk it:\n",
    "\n",
    "ds = xr.open_mfdataset(datasets)\n",
    "ds = ds.swap_dims({'obs': 'time'})\n",
    "ds = ds.chunk({'time': 100})\n",
    "ds = ds.sortby('time') # data from different deployments can overlap so we want to sort all data by time stamp.\n",
    "# Dropping not needed coordinates:\n",
    "ds3 = ds.drop(['time','obs','pressure','lat','lon'], dim=None)\n",
    "ds3\n",
    "\n",
    "g_temp = ds3.ctdpf_ckl_seawater_temperature.to_dataframe()\n",
    "#g_temp = g_temp.rename(columns={'ctdpf_ckl_seawater_temperature': 'temp'})\n",
    "\n",
    "g_salinity = ds3.practical_salinity.to_dataframe()\n",
    "#g_salinity = g_salinity.rename(columns={'practical_salinity': 'sal'})\n",
    "\n",
    "g_pressure = ds3.ctdpf_ckl_seawater_pressure.to_dataframe()\n",
    "\n",
    "g_conductivity = ds3.ctdpf_ckl_seawater_conductivity.to_dataframe()\n",
    "\n",
    "g_density = ds3.density.to_dataframe()\n",
    "\n",
    "# Joining tables to create dataset:\n",
    "gs_ctd = pd.concat([g_temp, g_salinity, g_conductivity, g_density],axis=1, join_axes=[g_temp.index])\n",
    "gs_ctd\n",
    "\n",
    "#Add a column for labeling: \n",
    "\n",
    "gs_ctd['Label']=0\n",
    "gs_ctd\n",
    "\n",
    "gs_rows = gs_ctd['Label'].shape\n",
    "\n",
    "# Decimate to 1% to make it faster:\n",
    "\n",
    "bins = int(.01*gs_rows[0]) #Saving only 10% because is just too much\n",
    "\n",
    "gs_file = gs_ctd.groupby(pd.qcut(gs_ctd.index,bins)).mean()\n",
    "\n",
    "\n",
    "gs_file.to_csv('gs_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Anaconda2]",
   "language": "python",
   "name": "Python [Anaconda2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
